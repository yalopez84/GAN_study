{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1oMMTHhkoPuO4thUl6aHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yalopez84/GAN_study/blob/master/Estudiando_KBGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTch7ZJ4SHYH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.optim import Adam, SGD, Adagrad\n",
        "from torch.autograd import Variable\n",
        "from random import randint\n",
        "from collections import defaultdict\n",
        "from numpy.random import choice, randint\n",
        "import numpy as n\n",
        "import datetime\n",
        "import yaml\n",
        "import sys\n",
        "import logging\n",
        "import subprocess\n",
        "from collections import namedtuple\n",
        "from itertools import count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model.py\n",
        "class BaseModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModule,self).__init__()\n",
        "    def score(self,src,rel,dst):\n",
        "        raise NotImplementedError\n",
        "    def dist(self,src,rel,dst):\n",
        "        raise NotImplementedError\n",
        "    def prob_logit(self,src,rel,dst):\n",
        "        raise NotImplementedError\n",
        "    def prob(self,src,rel,dst):\n",
        "        return f.softmax(self.prob_logit(src,rel,dst))\n",
        "    def constraint(self):\n",
        "        pass\n",
        "    def pair_loss(self,src,rel,dst, src_bad,dst_bad):\n",
        "        d_good=self.dist(src,rel,dst)\n",
        "        d_bad=self.dist(src_bad,rel,dst_bad)\n",
        "        return f.relu(self.margin + d_good - d_bad)\n",
        "\n",
        "    def softmax_loss(self, src, rel, dst, truth):\n",
        "        probs=self.prob(src,rel,dst)\n",
        "        n=probs.size(0)\n",
        "        truth_probs=t.log(probs[t.arange(0,n).type(t.LongTensor).cuda(),truth]+1e-30)\n",
        "        return -truth_probs\n",
        "\n",
        "class BaseModel(object):\n",
        "    def __init__(self):\n",
        "        self.mdl= None\n",
        "        self.weight_decay = 0\n",
        "    def save(self,filename):\n",
        "        t.save(self.mdl.state_dict(),filename)\n",
        "\n",
        "    def load(self,filename):\n",
        "        self.mdl.load_state_dict(t.load(filename,map_location=lambda storage, location:storage.cuda()))\n",
        "\n",
        "    def gen_step(self,src,rel,dst,n_sample=1,temperature=1.0,train=True):\n",
        "        if not hasattr(self,'opt'):\n",
        "            self.opt=Adam(self.mdl.parameters(), weight_decay=self.weight_decay)\n",
        "        n,m=dst.size()\n",
        "        rel_var=Variable(rel.cuda())\n",
        "        src_var = Variable(src.cuda())\n",
        "        dst_var = Variable(dst.cuda())\n",
        "        logits=self.mdl.prob_logit(src_var, rel_var, dst_var)/temperature\n",
        "        probs=f.softmax(logits)\n",
        "        row_idx=t.arange(0,n).type(t.LongTensor).unsqueeze(1).expand(n, n_sample)\n",
        "        sample_idx=t.multinomial(probs,n_sample, replacement=True)\n",
        "        sample_srcs = src[row_idx, sample_idx.data.cpu()]\n",
        "        sample_dsts = dst[row_idx, sample_idx.data.cpu()]\n",
        "        rewards = yield sample_srcs, sample_dsts\n",
        "        if train:\n",
        "            self.mdl.zero_grad()\n",
        "            log_probs = f.log_softmax(logits)\n",
        "            reinforce_loss = -t.sum(Variable(rewards) * log_probs[row_idx.cuda(), sample_idx.data])\n",
        "            reinforce_loss.backward()\n",
        "            self.opt.step()\n",
        "            self.mdl.constraint()\n",
        "        yield None\n",
        "\n",
        "    def dis_step(self,src, rel, dst, src_fake, dst_fake, train=True):\n",
        "        if not hasattr(self,'opt'):\n",
        "            self.opt = Adam(self.mdl.parameters(), weight_decay=self.weight_decay)\n",
        "        src_var = Variable(src.cuda())\n",
        "        rel_var = Variable(rel.cuda())\n",
        "        dst_var = Variable(dst.cuda())\n",
        "        src_fake_var = Variable(src_fake.cuda())\n",
        "        dst_fake_var = Variable(dst_fake.cuda())\n",
        "        losses = self.mdl.pair_loss(src_var, rel_var, dst_var, src_fake_var, dst_fake_var)\n",
        "        fake_scores = self.mdl.score(src_fake_var, rel_var, dst_fake_var)\n",
        "        if train:\n",
        "            self.mdl.zero_grad()\n",
        "            t.sum(losses).backward()\n",
        "            self.opt.step()\n",
        "            self.mdl.constraint()\n",
        "        return losses.data, -fake_scores.data\n",
        "\n",
        "    def test_link(self, test_data, n_ent, heads, tails, filt=True):\n",
        "        mrr_tot = 0\n",
        "        mr_tot = 0\n",
        "        hit10_tot = 0\n",
        "        count = 0\n",
        "        for batch_s, batch_r, batch_t in batch_by_size(config().test_batch_size, *test_data):\n",
        "            batch_size = batch_s.size(0)\n",
        "            rel_var = Variable(batch_r.unsqueeze(1).expand(batch_size, n_ent).cuda())\n",
        "            src_var = Variable(batch_s.unsqueeze(1).expand(batch_size, n_ent).cuda())\n",
        "            dst_var = Variable(batch_t.unsqueeze(1).expand(batch_size, n_ent).cuda())\n",
        "            all_var = Variable(t.arange(0, n_ent).unsqueeze(0).expand(batch_size, n_ent)\n",
        "                               .type(t.LongTensor).cuda(), volatile=True)\n",
        "            batch_dst_scores = self.mdl.score(src_var, rel_var, all_var).data\n",
        "            batch_src_scores = self.mdl.score(all_var, rel_var, dst_var).data\n",
        "            for s, r, t, dst_scores, src_scores in zip(batch_s, batch_r, batch_t, batch_dst_scores, batch_src_scores):\n",
        "                if filt:\n",
        "                    if tails[(s, r)]._nnz() > 1:\n",
        "                        tmp = dst_scores[t]\n",
        "                        dst_scores += tails[(s, r)].cuda() * 1e30\n",
        "                        dst_scores[t] = tmp\n",
        "                    if heads[(t, r)]._nnz() > 1:\n",
        "                        tmp = src_scores[s]\n",
        "                        src_scores += heads[(t, r)].cuda() * 1e30\n",
        "                        src_scores[s] = tmp\n",
        "                mrr, mr, hit10 = mrr_mr_hitk(dst_scores, t)\n",
        "                mrr_tot += mrr\n",
        "                mr_tot += mr\n",
        "                hit10_tot += hit10\n",
        "                mrr, mr, hit10 = mrr_mr_hitk(src_scores, s)\n",
        "                mrr_tot += mrr\n",
        "                mr_tot += mr\n",
        "                hit10_tot += hit10\n",
        "                count += 2\n",
        "        logging.info('Test_MRR=%f, Test_MR=%f, Test_H@10=%f', mrr_tot / count, mr_tot / count, hit10_tot / count)\n",
        "        return mrr_tot / count\n",
        "\n"
      ],
      "metadata": {
        "id": "iok96m3hTzko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_utils.py\n",
        "def heads_tails(n_ent, train_data, valid_data=None, test_data=None):\n",
        "    train_src, train_rel, train_dst = train_data\n",
        "    if valid_data:\n",
        "        valid_src, valid_rel, valid_dst = valid_data\n",
        "    else:\n",
        "        valid_src = valid_rel = valid_dst = []\n",
        "    if test_data:\n",
        "        test_src, test_rel, test_dst = test_data\n",
        "    else:\n",
        "        test_src = test_rel = test_dst = []\n",
        "    all_src = train_src + valid_src + test_src\n",
        "    all_rel = train_rel + valid_rel + test_rel\n",
        "    all_dst = train_dst + valid_dst + test_dst\n",
        "    heads = defaultdict(lambda: set())\n",
        "    tails = defaultdict(lambda: set())\n",
        "    for s, r, t in zip(all_src, all_rel, all_dst):\n",
        "        tails[(s, r)].add(t)\n",
        "        heads[(t, r)].add(s)\n",
        "    heads_sp = {}\n",
        "    tails_sp = {}\n",
        "    for k in tails.keys():\n",
        "        tails_sp[k] = t.sparse.FloatTensor(t.LongTensor([list(tails[k])]),\n",
        "                                               t.ones(len(tails[k])), t.Size([n_ent]))\n",
        "    for k in heads.keys():\n",
        "        heads_sp[k] = t.sparse.FloatTensor(t.LongTensor([list(heads[k])]),\n",
        "                                               t.ones(len(heads[k])), t.Size([n_ent]))\n",
        "    return heads_sp, tails_sp\n",
        "\n",
        "\n",
        "def inplace_shuffle(*lists):\n",
        "    idx = []\n",
        "    for i in range(len(lists[0])):\n",
        "        idx.append(randint(0, i))\n",
        "    for ls in lists:\n",
        "        for i, item in enumerate(ls):\n",
        "            j = idx[i]\n",
        "            ls[i], ls[j] = ls[j], ls[i]\n",
        "\n",
        "\n",
        "def batch_by_num(n_batch, *lists, n_sample=None):\n",
        "    if n_sample is None:\n",
        "        n_sample = len(lists[0])\n",
        "    for i in range(n_batch):\n",
        "        head = int(n_sample * i / n_batch)\n",
        "        tail = int(n_sample * (i + 1) / n_batch)\n",
        "        ret = [ls[head:tail] for ls in lists]\n",
        "        if len(ret) > 1:\n",
        "            yield ret\n",
        "        else:\n",
        "            yield ret[0]\n",
        "\n",
        "def batch_by_size(batch_size, *lists, n_sample=None):\n",
        "    if n_sample is None:\n",
        "        n_sample = len(lists[0])\n",
        "    head = 0\n",
        "    while head < n_sample:\n",
        "        tail = min(n_sample, head + batch_size)\n",
        "        ret = [ls[head:tail] for ls in lists]\n",
        "        head += batch_size\n",
        "        if len(ret) > 1:\n",
        "            yield ret\n",
        "        else:\n",
        "            yield ret[0]"
      ],
      "metadata": {
        "id": "U9-d4Nx7RmKR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#config.py\n",
        "\n",
        "class ConfigDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "\n",
        "def _make_config_dict(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return ConfigDict({k: _make_config_dict(v) for k, v in obj.items()})\n",
        "    elif isinstance(obj, list):\n",
        "        return [_make_config_dict(x) for x in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "_config = None\n",
        "\n",
        "def config():\n",
        "    global _config\n",
        "    if _config is None:\n",
        "        config_path = 'config.yaml'\n",
        "        for arg in sys.argv[1:]:\n",
        "            if arg.startswith('--config='):\n",
        "                config_path = arg[9:]\n",
        "                break\n",
        "        print('Reading config from ' + config_path)\n",
        "        with open(config_path) as f:\n",
        "            _config = _make_config_dict(yaml.load(f))\n",
        "        overwrite_config_with_args()\n",
        "    return _config\n",
        "\n",
        "def path_set(path, val, sep='.', auto_convert=False):\n",
        "    steps = path.split(sep)\n",
        "    obj = _config\n",
        "    for step in steps[:-1]:\n",
        "        obj = obj[step]\n",
        "    old_val = obj[steps[-1]]\n",
        "    if not auto_convert:\n",
        "        obj[steps[-1]] = val\n",
        "    elif isinstance(old_val, bool):\n",
        "        obj[steps[-1]] = val.lower() == 'true'\n",
        "    elif isinstance(old_val, float):\n",
        "        obj[steps[-1]] = float(val)\n",
        "    elif isinstance(old_val, int):\n",
        "        try:\n",
        "            obj[steps[-1]] = int(val)\n",
        "        except ValueError:\n",
        "            obj[steps[-1]] = float(val)\n",
        "    else:\n",
        "        obj[steps[-1]] = val\n",
        "\n",
        "def overwrite_config_with_args(args=None, sep='.'):\n",
        "    if args is None:\n",
        "        args = sys.argv[1:]\n",
        "    for arg in args:\n",
        "        if arg.startswith('--') and '=' in arg:\n",
        "            path, val = arg[2:].split('=')\n",
        "            if path != 'config':\n",
        "                path_set(path, val, sep, auto_convert=True)\n",
        "\n",
        "def _dump_config(obj, prefix):\n",
        "    if isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            _dump_config(v, prefix + (k,))\n",
        "    elif isinstance(obj, list):\n",
        "        for i, v in enumerate(obj):\n",
        "            _dump_config(v, prefix + (str(i),))\n",
        "    else:\n",
        "        if isinstance(obj, str):\n",
        "            rep = obj\n",
        "        else:\n",
        "            rep = repr(obj)\n",
        "        logging.debug('%s=%s', '.'.join(prefix), rep)\n",
        "\n",
        "def dump_config():\n",
        "    return _dump_config(_config, tuple())"
      ],
      "metadata": {
        "id": "BKH-NlZYS9ox"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics.py\n",
        "def mrr_mr_hitk(scores, target, k=10):\n",
        "    _, sorted_idx = t.sort(scores)\n",
        "    find_target = sorted_idx == target\n",
        "    target_rank = t.nonzero(find_target)[0, 0] + 1\n",
        "    return 1 / target_rank, target_rank, int(target_rank <= k)"
      ],
      "metadata": {
        "id": "Mnasg894VZJs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#corrupter.py\n",
        "def get_bern_prob(data, n_ent, n_rel):\n",
        "    src, rel, dst = data\n",
        "    edges = defaultdict(lambda: defaultdict(lambda: set()))\n",
        "    rev_edges = defaultdict(lambda: defaultdict(lambda: set()))\n",
        "    for s, r, t in zip(src, rel, dst):\n",
        "        edges[r][s].add(t)\n",
        "        rev_edges[r][t].add(s)\n",
        "    bern_prob = t.zeros(n_rel)\n",
        "    for r in edges.keys():\n",
        "        tph = sum(len(tails) for tails in edges[r].values()) / len(edges[r])\n",
        "        htp = sum(len(heads) for heads in rev_edges[r].values()) / len(rev_edges[r])\n",
        "        bern_prob[r] = tph / (tph + htp)\n",
        "    return bern_prob\n",
        "\n",
        "class BernCorrupter(object):\n",
        "    def __init__(self, data, n_ent, n_rel):\n",
        "        self.bern_prob = get_bern_prob(data, n_ent, n_rel)\n",
        "        self.n_ent = n_ent\n",
        "\n",
        "    def corrupt(self, src, rel, dst):\n",
        "        prob = self.bern_prob[rel]\n",
        "        selection = t.bernoulli(prob).numpy().astype('int64')\n",
        "        ent_random = choice(self.n_ent, len(src))\n",
        "        src_out = (1 - selection) * src.numpy() + selection * ent_random\n",
        "        dst_out = selection * dst.numpy() + (1 - selection) * ent_random\n",
        "        return t.from_numpy(src_out), t.from_numpy(dst_out)\n",
        "\n",
        "class BernCorrupterMulti(object):\n",
        "    def __init__(self, data, n_ent, n_rel, n_sample):\n",
        "        self.bern_prob = get_bern_prob(data, n_ent, n_rel)\n",
        "        self.n_ent = n_ent\n",
        "        self.n_sample = n_sample\n",
        "\n",
        "    def corrupt(self, src, rel, dst, keep_truth=True):\n",
        "        n = len(src)\n",
        "        prob = self.bern_prob[rel]\n",
        "        selection = t.bernoulli(prob).numpy().astype('bool')\n",
        "        src_out = n.tile(src.numpy(), (self.n_sample, 1)).transpose()\n",
        "        dst_out = n.tile(dst.numpy(), (self.n_sample, 1)).transpose()\n",
        "        rel_out = rel.unsqueeze(1).expand(n, self.n_sample)\n",
        "        if keep_truth:\n",
        "            ent_random = choice(self.n_ent, (n, self.n_sample - 1))\n",
        "            src_out[selection, 1:] = ent_random[selection]\n",
        "            dst_out[~selection, 1:] = ent_random[~selection]\n",
        "        else:\n",
        "            ent_random = choice(self.n_ent, (n, self.n_sample))\n",
        "            src_out[selection, :] = ent_random[selection]\n",
        "            dst_out[~selection, :] = ent_random[~selection]\n",
        "        return t.from_numpy(src_out), rel_out, t.from_numpy(dst_out)"
      ],
      "metadata": {
        "id": "6vTg8ojpcZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gan_train.py\n",
        "logger_init()\n",
        "t.cuda.set_device(select_gpu())\n",
        "overwrite_config_with_args()\n",
        "dump_config()\n",
        "task_dir = config().task.dir\n",
        "kb_index = index_ent_rel(os.path.join(task_dir, 'train.txt'),\n",
        "                         os.path.join(task_dir, 'valid.txt'),\n",
        "                         os.path.join(task_dir, 'test.txt'))\n",
        "n_ent, n_rel = graph_size(kb_index)\n",
        "models = {'TransE': TransE, 'TransD': TransD, 'DistMult': DistMult, 'ComplEx': ComplEx}\n",
        "Aqui Me quede.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "YJYJJAsYlZjT",
        "outputId": "db0a1eef-c309-4966-c03c-f94ffdbdddb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading config from config.yaml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3d38ac312e19>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#gan_train.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogger_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-8c092508df4e>\u001b[0m in \u001b[0;36mlogger_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogger_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%(module)15s %(asctime)s %(message)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         log_filename = os.path.join(config().log.dir,\n\u001b[1;32m      6\u001b[0m                                     config().log.prefix + datetime.datetime.now().strftime(\"%m%d%H%M%S\"))\n",
            "\u001b[0;32m<ipython-input-3-82d9b7d82fcd>\u001b[0m in \u001b[0;36mconfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading config from '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0m_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moverwrite_config_with_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.yaml'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logger_init.py\n",
        "def logger_init():\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(module)15s %(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
        "    if config().log.to_file:\n",
        "        log_filename = os.path.join(config().log.dir,\n",
        "                                    config().log.prefix + datetime.datetime.now().strftime(\"%m%d%H%M%S\"))\n",
        "        logging.getLogger().addHandler(logging.FileHandler(log_filename))\n",
        "    if config().log.dump_config:\n",
        "        dump_config()"
      ],
      "metadata": {
        "id": "RycKiB3yl1BQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read_data.py\n",
        "KBIndex = namedtuple('KBIndex', ['ent_list', 'rel_list', 'ent_id', 'rel_id'])\n",
        "def index_ent_rel(*filenames):\n",
        "    ent_set = set()\n",
        "    rel_set = set()\n",
        "    for filename in filenames:\n",
        "        with open(filename) as f:\n",
        "            for ln in f:\n",
        "                s, r, t = ln.strip().split('\\t')[:3]\n",
        "                ent_set.add(s)\n",
        "                ent_set.add(t)\n",
        "                rel_set.add(r)\n",
        "    ent_list = sorted(list(ent_set))\n",
        "    rel_list = sorted(list(rel_set))\n",
        "    ent_id = dict(zip(ent_list, count()))\n",
        "    rel_id = dict(zip(rel_list, count()))\n",
        "    return KBIndex(ent_list, rel_list, ent_id, rel_id)\n",
        "\n",
        "\n",
        "def graph_size(kb_index):\n",
        "    return len(kb_index.ent_id), len(kb_index.rel_id)\n",
        "\n",
        "\n",
        "def read_data(filename, kb_index):\n",
        "    src = []\n",
        "    rel = []\n",
        "    dst = []\n",
        "    with open(filename) as f:\n",
        "        for ln in f:\n",
        "            s, r, t = ln.strip().split('\\t')\n",
        "            src.append(kb_index.ent_id[s])\n",
        "            rel.append(kb_index.rel_id[r])\n",
        "            dst.append(kb_index.ent_id[t])\n",
        "    return src, rel, dst"
      ],
      "metadata": {
        "id": "3NahowWApgJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#select_gpu.py\n",
        "def select_gpu():\n",
        "    nvidia_info = subprocess.run('nvidia-smi', stdout=subprocess.PIPE)\n",
        "    gpu_info = False\n",
        "    gpu_info_line = 0\n",
        "    proc_info = False\n",
        "    gpu_mem = []\n",
        "    gpu_occupied = set()\n",
        "    for line in nvidia_info.stdout.split(b'\\n'):\n",
        "        line = line.decode().strip()\n",
        "        if gpu_info:\n",
        "            gpu_info_line += 1\n",
        "            if line == '':\n",
        "                gpu_info = False\n",
        "                continue\n",
        "            if gpu_info_line % 3 == 2:\n",
        "                mem_info = line.split('|')[2]\n",
        "                used_mem_mb = int(mem_info.strip().split()[0][:-3])\n",
        "                gpu_mem.append(used_mem_mb)\n",
        "        if proc_info:\n",
        "            if line == '|  No running processes found                                                 |':\n",
        "                continue\n",
        "            if line == '+-----------------------------------------------------------------------------+':\n",
        "                proc_info = False\n",
        "                continue\n",
        "            proc_gpu = int(line.split()[1])\n",
        "            #proc_type = line.split()[3]\n",
        "            gpu_occupied.add(proc_gpu)\n",
        "        if line == '|===============================+======================+======================|':\n",
        "            gpu_info = True\n",
        "        if line == '|=============================================================================|':\n",
        "            proc_info = True\n",
        "    for i in range(len(gpu_mem)):\n",
        "        if i not in gpu_occupied:\n",
        "            logging.info('Automatically selected GPU %d because it is vacant.', i)\n",
        "            return i\n",
        "    for i in range(len(gpu_mem)):\n",
        "        if gpu_mem[i] == min(gpu_mem):\n",
        "            logging.info('All GPUs are occupied. Automatically selected GPU %d because it has the most free memory.', i)\n",
        "            return i\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(select_gpu())"
      ],
      "metadata": {
        "id": "c4lbSFE8yK7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}